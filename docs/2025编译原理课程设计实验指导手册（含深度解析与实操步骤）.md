## 目录

1. 实验概述（核心任务 + 学习目标）

2. 实验原理深度拆解（结合理论与实操逻辑）

3. 详细实验步骤（分场景 + 代码示例）

4. 调试技巧与常见问题解决方案

5. 考核标准解读与提交物规范

6. 拓展建议（提升实验质量的优化方向）

## 一、实验概述

### 1.1 核心任务（基于编译原理课设共性 + 常见要求）

编译原理课程设计的核心是实现**编译器前端核心模块**，最常见任务为以下两类：

- 基础任务：设计并实现一个**词法分析器**，能将高级语言源程序（如 PL/0、C 语言子集）分解为单词符号（Token），输出`(单词种类码, 单词值)`二元组；

- 进阶任务：在词法分析器基础上，实现**语法分析器**（LL (1)/SLR (1)），通过语法规则验证 Token 流的合法性，生成抽象语法树（AST）或直接输出语法分析结果。

### 1.2 实验学习目标

- 掌握词法分析的核心原理：正则式→NFA→DFA→最小化 DFA 的完整流程；

- 理解语法分析的本质：文法改造（左递归消除、左公共因子提取）→ FIRST/FOLLOW 集计算→ 分析表构造→ 表驱动分析；

- 具备工程实现能力：能用 C/C++/Python 等语言手动实现状态机，或用 Flex/Bison 工具快速构建分析器；

- 培养问题排查能力：能识别并解决词法 / 语法错误（如非法字符、括号不匹配、语法结构异常）。

### 1.3 实验环境准备

#### 1.3.1 开发工具

- 手动实现：IDE（Visual Studio、CLion、VS Code）+ 编译器（GCC/G++、MinGW）；

- 工具实现：Flex（词法分析生成器）+ Bison（语法分析生成器）+ 终端（Linux/macOS）或 WSL（Windows）；

- 辅助工具：YatCC-AI 智能编译平台（可选，云端环境无需配置，支持 AI 辅助开发与测试）。

#### 1.3.2 前置知识储备

- 词法分析：正则表达式、有限自动机（NFA/DFA）、状态转移图；

- 语法分析：上下文无关文法（CFG）、LL (1)/SLR (1) 文法判定、分析表构造；

- 编程基础：文件读写、字符串处理、数据结构（数组、哈希表、栈）。

## 二、实验原理深度拆解（直击核心 + 用户易混淆点）

### 2.1 词法分析器核心原理

#### 2.1.1 核心任务

将源程序中的字符流转换为**单词符号流**（Token），单词类型包括：

- 关键字（if、else、begin、end 等）；

- 标识符（变量名、函数名）；

- 常量（整数、浮点数、字符串）；

- 运算符（+、-、\*、/、\==、<= 等）；

- 界符（;、,、(、)、{、} 等）。

#### 2.1.2 关键流程（用户易混淆点突破）

1. **单词表定义**：先明确所有合法单词的类型、助记符、种别编码（示例如下）：

| 种别编码 | 单词符号 | 助记符 | 说明 |
|----------|----------|--------|------|
| 1        | if       | IF     | 关键字 |
| 2        | else     | ELSE   | 关键字 |
| 3        | 字母 {字母 / 数字} | ID | 标识符 |
| 4        | 数字 {数字} | NUM | 整数常量 |
| 5        | ==       | EQ     | 关系运算符 |
| 6        | ;        | SEMI   | 界符 |

2. **正则式→NFA→DFA→最小化 DFA**（用户核心困惑点解析）：

- 正则式：用符号描述单词的模式（如标识符→`letter(letter|digit)*`，整数→`digit+`）；

- NFA 构造：每个正则式对应一个 NFA（含初始态、终止态、ε 边），处理 “或”“重复” 等逻辑；

- NFA 转 DFA：用**子集法**（之前重点讲解），将 NFA 的 “多状态并行” 打包为 DFA 的 “单状态”（如 NFA 中 S 读 1 同时到 S 和 R，DFA 中对应状态 {SR}）；

- DFA 最小化：合并等价状态（输入相同字符转移到同一状态），减少代码复杂度。

1. **状态转移表设计**（替代复杂分支判断）：
将 DFA 的状态转移逻辑抽象为二维数组`stateTrans[当前状态][输入字符类型] = 下一状态`，示例如下（简化版）：

| 当前状态 \ 输入类型 | 空白符 | 字母 | 数字 | == | ; | 其他 |
|--------------------|--------|------|------|----|---|------|
| 0（初始态）        | 0      | 1    | 3    | 5  | 6 | 错误 |
| 1（标识符初态）    | 2（终态）| 1  | 1    | 2  | 2 | 2    |
| 3（数字初态）      | 4（终态）| 错误 | 3  | 4  | 4 | 4    |

### 2.2 语法分析器核心原理

#### 2.2.1 核心任务

验证词法分析器输出的 Token 流是否符合文法规则，例如：`if (expr) stmt else stmt` 是合法结构，而 `if (expr) else stmt` 是非法结构。

#### 2.2.2 关键流程（以 LL (1) 文法为例）

1. **文法改造**（前提条件）：

- 消除左递归：直接左递归（A→Aα|β）→ 改造为 A→βA'，A'→αA'|ε；

- 提取左公共因子：A→αβ1|αβ2→ 改造为 A→αA'，A'→β1|β2；

- 目的：避免分析时 “回溯”，保证 LL (1) 的 “确定性”。

1. **FIRST/FOLLOW 集计算**（分析表构造基础）：

- FIRST 集：某符号能推导出的首终结符集合（如 FIRST (expr)={NUM, ID, (}）；

- FOLLOW 集：某非终结符后可能出现的终结符集合（如 FOLLOW (S)={#, )}）；

- 计算技巧：FIRST 集 “自上而下” 推导，FOLLOW 集 “自下而上” 传递（参考之前例题）。

1. **LL (1) 分析表构造**：
二维表`M[非终结符][终结符] = 产生式`，构造规则：

- 若 α∈FIRST (A)，则 M [A][α] = A→α；

- 若 ε∈FIRST (A) 且 β∈FOLLOW (A)，则 M [A][β] = A→ε；

- 示例：M [stmt][if] = stmt→if (expr) stmt else stmt。

1. **表驱动分析过程**：
用栈存储非终结符，按分析表规则推导：

- 初始化栈：[#，开始符 S]，输入指针指向第一个 Token；

- 循环：弹出栈顶符号，若为终结符则与当前 Token 匹配，否则查分析表执行产生式替换；

- 终止：栈顶为 #且输入结束→分析成功；否则→语法错误。

## 三、详细实验步骤（分场景 + 可直接复用代码）

### 3.1 场景 1：手动实现词法分析器（C 语言示例）

#### 步骤 1：定义数据结构与常量

```c

#include <stdio.h>
#include <string.h>
#include <ctype.h>

// 单词种别编码
#define IF 1
#define ELSE 2
#define ID 3
#define NUM 4
#define EQ 5
#define SEMI 6
#define ERROR 0

// 关键字表（用哈希表更高效，简化版用数组）
char *reservedWords[] = {"if", "else", NULL};
// 状态转移表（行：状态，列：输入类型0-5：空白符、字母、数字、==、;、其他）
int stateTrans[7][6] = {
    {0, 1, 3, 5, 6, ERROR}, // 状态0（初始态）
    {2, 1, 1, 2, 2, 2},     // 状态1（标识符初态）
    {2, 2, 2, 2, 2, 2},     // 状态2（标识符终态）
    {4, ERROR, 3, 4, 4, 4}, // 状态3（数字初态）
    {4, 4, 4, 4, 4, 4},     // 状态4（数字终态）
    {5, 5, 5, 5, 5, 5},     // 状态5（==终态）
    {6, 6, 6, 6, 6, 6}      // 状态6（;终态）
};

char token[50]; // 存储当前识别的单词
int tokenLen = 0; // token长度
```

#### 步骤 2：实现辅助函数

```c

// 读取一个字符（跳过注释，处理文件结束）
char getch(FILE *fin) {
    char c = fgetc(fin);
    // 处理单行注释（//开头）
    if (c == '/') {
        char next = fgetc(fin);
        if (next == '/') {
            while ((c = fgetc(fin)) != '\n' && c != EOF);
        } else {
            ungetc(next, fin); // 回退字符
        }
    }
    return c;
}

// 判断字符类型（返回0-5）
int charType(char c) {
    if (isspace(c)) return 0;
    if (isalpha(c) || c == '_') return 1;
    if (isdigit(c)) return 2;
    if (c == '=') { // 需判断下一个字符是否为=
        return 3;
    }
    if (c == ';') return 4;
    return 5;
}

// 判断是否为关键字（是则返回对应编码，否则返回ID）
int isReserved(char *str) {
    for (int i = 0; reservedWords[i] != NULL; i++) {
        if (strcmp(str, reservedWords[i]) == 0) {
            return i + 1; // if返回1，else返回2
        }
    }
    return ID;
}
```

#### 步骤 3：实现词法分析主函数

```c

int lexer(FILE *fin) {
    int currentState = 0;
    tokenLen = 0;
    memset(token, 0, sizeof(token));
    
    while (1) {
        char c = getch(fin);
        if (c == EOF) return EOF;
        
        int type = charType(c);
        currentState = stateTrans[currentState][type];
        
        if (currentState == ERROR) {
            // 非法字符处理
            token[tokenLen++] = c;
            token[tokenLen] = '\0';
            printf("词法错误：非法字符 %s\n", token);
            return ERROR;
        }
        
        // 终态处理：识别到完整单词
        if (currentState == 2 || currentState == 4 || currentState == 5 || currentState == 6) {
            if (type != 0) { // 非空白符加入token
                token[tokenLen++] = c;
                // 处理双字符运算符（如==）
                if (currentState == 5) {
                    char next = fgetc(fin);
                    if (next == '=') {
                        token[tokenLen++] = next;
                    } else {
                        ungetc(next, fin); // 回退，仅识别=（需在状态表中补充=的处理）
                    }
                }
            }
            token[tokenLen] = '\0';
            // 判断单词类型并返回
            switch (currentState) {
                case 2: return isReserved(token);
                case 4: return NUM;
                case 5: return EQ;
                case 6: return SEMI;
                default: return ERROR;
            }
        } else if (currentState != 0) {
            // 非终态且非初始态，加入token
            token[tokenLen++] = c;
        }
    }
}
```

#### 步骤 4：测试词法分析器

```c

int main() {
    FILE *fin = fopen("input.txt", "r"); // 输入源程序文件
    FILE *fout = fopen("output.txt", "w"); // 输出Token流
    if (!fin || !fout) {
        printf("文件打开失败！\n");
        return 1;
    }
    
    int type;
    while ((type = lexer(fin)) != EOF) {
        if (type == ERROR) continue;
        // 输出二元组 (种别编码, 单词值)
        fprintf(fout, "(%d, %s)\n", type, token);
        printf("(%d, %s)\n", type, token);
    }
    
    fclose(fin);
    fclose(fout);
    return 0;
}
```

### 3.2 场景 2：用 Flex+Bison 实现词法 + 语法分析器（计算器示例）

#### 步骤 1：编写 Flex 词法规则文件（calc.l）

```c

%{
#include "y.tab.h" // 包含Bison生成的Token定义
%}

%%
// 规则：正则表达式 → 动作（返回Token）
[0-9]+          { yylval = atoi(yytext); return NUMBER; } // 整数常量
"+"             { return PLUS; } // 加法运算符
"-"             { return MINUS; } // 减法运算符
"*"             { return MUL; } // 乘法运算符
"/"             { return DIV; } // 除法运算符
"("             { return LPAREN; } // 左括号
")"             { return RPAREN; } // 右括号
[ \t\n]+        { /* 忽略空白符 */ } // 跳过空格、制表符、换行符
.               { yyerror("非法字符"); } // 其他字符报错
%%

int yywrap() { return 1; } // 结束标志
```

#### 步骤 2：编写 Bison 语法规则文件（calc.y）

```c

%{
#include <stdio.h>
extern int yylex(); // Flex生成的词法分析函数
void yyerror(const char *s) { fprintf(stderr, "语法错误：%s\n", s); } // 错误处理函数
%}

// 声明Token类型
%token NUMBER PLUS MINUS MUL DIV LPAREN RPAREN

// 语法规则（优先级：括号 > 乘除 > 加减）
%%
lines: lines expr '\n'    { printf("计算结果：%d\n", $2); } // 一行表达式
     | lines '\n'         { /* 空行忽略 */ }
     | /* 空 */           { /* 起始规则 */ }
     ;

expr: expr PLUS term      { $$ = $1 + $3; } // 加法表达式
    | expr MINUS term     { $$ = $1 - $3; } // 减法表达式
    | term                { $$ = $1; } // 表达式→项
    ;

term: term MUL factor     { $$ = $1 * $3; } // 乘法项
    | term DIV factor     { $$ = $1 / $3; } // 除法项
    | factor              { $$ = $1; } // 项→因子
    ;

factor: LPAREN expr RPAREN{ $$ = $2; } // 因子→(表达式)
      | NUMBER            { $$ = $1; } // 因子→整数
      ;
%%

int main() {
    printf("请输入表达式（每行一个，按回车计算）：\n");
    yyparse(); // 调用语法分析函数
    return 0;
}
```

#### 步骤 3：编译与运行（终端命令）

1. 生成 Bison 代码：`bison -d calc.y`（生成 y.tab.c 和 y.tab.h）；

2. 生成 Flex 代码：`flex calc.l`（生成 lex.yy.c）；

3. 编译链接：`gcc lex.yy.c y.tab.c -o calculator -lfl`（-lfl 链接 Flex 库）；

4. 运行程序：`./calculator`（输入表达式如 “3+5*2”，输出结果 13）。

### 3.3 场景 3：手动实现 LL (1) 语法分析器（基于词法分析器）

#### 步骤 1：基于词法分析器，补充文法与分析表

```c

// 非终结符：E(表达式)、T(项)、E'(E的后继)、T'(T的后继)、F(因子)
// 产生式：
// E→TE'
// E'→+TE' | ε
// T→FT'
// T'→*FT' | ε
// F→(E) | ID | NUM

// FIRST集（简化版）
char *FIRST[] = {"i(", "i(", "+", ε, "i(", "*", "i(", "i(", "i("};
// FOLLOW集（简化版）
char *FOLLOW[] = {")#", ")*+#", ")*+#", ")*+#", ")*+#", ")*+#", ")*+#"};
// LL(1)分析表（行：非终结符，列：终结符i、+、*、(、)、#）
char *LL1Table[7][6] = {
    {"TE'", "error", "error", "TE'", "error", "error"},
    {"error", "+TE'", "error", "error", "ε", "ε"},
    {"FT'", "error", "error", "FT'", "error", "error"},
    {"error", "ε", "*FT'", "error", "ε", "ε"},
    {"i", "error", "error", "(E)", "error", "error"}
};
```

#### 步骤 2：实现语法分析主函数（用栈）

```c

#include <stack.h> // 需自行实现栈或用数组模拟

void ll1Parser(FILE *fin) {
    Stack *stack = initStack();
    push(stack, '#');
    push(stack, 'E'); // 开始符入栈
    
    int currentToken = lexer(fin); // 读取第一个Token
    while (stackTop(stack) != '#') {
        char top = stackTop(stack);
        if (isTerminal(top)) { // 栈顶是终结符
            if (top == tokenToTerminal(currentToken)) {
                pop(stack);
                currentToken = lexer(fin);
            } else {
                printf("语法错误：预期 %c，实际 %s\n", top, token);
                return;
            }
        } else { // 栈顶是非终结符，查分析表
            int row = nonTerminalIndex(top);
            int col = terminalIndex(currentToken);
            char *prod = LL1Table[row][col];
            if (strcmp(prod, "error") == 0) {
                printf("语法错误：非终结符 %c 遇到Token %s\n", top, token);
                return;
            }
            pop(stack);
            if (strcmp(prod, "ε") != 0) { // 产生式不为空，逆序入栈
                for (int i = strlen(prod)-1; i >= 0; i--) {
                    push(stack, prod[i]);
                }
            }
        }
    }
    printf("语法分析成功：输入符合文法规则！\n");
}
```

## 四、调试技巧与常见问题解决方案

### 4.1 词法分析器常见问题

#### 问题 1：标识符与关键字混淆

- 原因：关键字是特殊的标识符，未优先判断；

- 解决：识别到字母开头的单词后，先查关键字表，再判定为标识符。

#### 问题 2：双字符运算符（如 \==、<=）识别错误

- 原因：未处理 “超前看”（Lookahead）；

- 解决：读取到 = 时，再读下一个字符，若为 = 则合并为 \==，否则回退字符。

#### 问题 3：状态转移逻辑混乱

- 原因：状态转移表设计错误；

- 解决：先手绘 DFA 状态转移图，再对照图填写状态转移表，用简单测试用例（如 “a123”“5\==3”）验证。

### 4.2 语法分析器常见问题

#### 问题 1：LL (1) 分析表存在冲突

- 原因：文法未完全消除左递归或左公共因子；

- 解决：重新检查文法，确保无左递归、无左公共因子，重新计算 FIRST/FOLLOW 集。

#### 问题 2：栈溢出或死循环

- 原因：产生式替换逻辑错误（如漏写 ε 产生式）；

- 解决：确保所有非终结符的 FOLLOW 集计算正确，ε 产生式在合适的位置应用。

#### 问题 3：语法错误定位不准

- 原因：未记录 Token 的行号和列号；

- 解决：在词法分析器中添加行号、列号计数，报错时输出 “行 x 列 y：语法错误”。

### 4.3 通用调试技巧

1. 打印中间状态：词法分析时打印`当前状态、输入字符、token`，语法分析时打印`栈内容、当前Token、使用的产生式`；

2. 设计测试用例：从简单到复杂（如先测试单个标识符，再测试表达式，最后测试完整语句）；

3. 逐步调试：用 IDE 的断点功能，单步执行，观察变量变化（如 stateTrans 的返回值、栈的进出情况）；

4. 参考标准实现：对比 LLVM/Clang 的词法 / 语法分析逻辑，或使用 YatCC-AI 平台的 AI 辅助调试功能。

## 五、考核标准解读与提交物规范

### 5.1 考核核心要点（多数高校课设通用）

1. 功能完整性：词法分析器能识别所有合法单词，语法分析器能正确处理合法 / 非法输入；

2. 代码规范性：命名规范、注释清晰、结构合理（模块化设计，如词法分析、语法分析分离）；

3. 错误处理能力：能识别并提示词法错误（非法字符）、语法错误（括号不匹配、语法结构异常）；

4. 理论应用：正确应用 NFA→DFA、LL (1)/SLR (1) 分析表等核心理论，而非单纯调用工具。

### 5.2 提交物清单（按要求整理）

1. 源程序代码：所有.c/.h 文件、Flex 的.l 文件、Bison 的.y 文件（需标注版本和功能）；

2. 实验报告：含实验目的、原理、步骤、代码说明、测试用例、运行结果、问题与解决方法；

3. 可执行程序：编译后的.exe 文件（Windows）或二进制文件（Linux/macOS）；

4. 测试用例：输入文件（.txt）、预期输出文件、实际输出文件（对比验证）；

5. 附加材料（加分项）：状态转移图、语法树可视化截图、性能优化说明。

## 六、拓展建议（提升实验质量）

1. 功能拓展：在词法分析器中添加字符串常量、浮点数识别，在语法分析器中支持 if-else、while 循环语句；

2. 性能优化：DFA 最小化、状态转移表压缩（用哈希表替代二维数组）、Token 缓存；

3. 可视化：用 Graphviz 绘制 DFA 状态转移图、语法分析树（AST），让实验结果更直观；

4. 工具进阶：学习 Flex 的正则式优化、Bison 的错误恢复机制，或尝试用 Python 的 PLY 库（Flex+Bison 的 Python 版本）实现；

5. 前沿探索：了解 LLVM 框架，尝试将语法分析结果生成 LLVM IR（中间表示），为后续代码生成做铺垫。

---

### 说明

1. 本手册基于编译原理课设通用要求编写，若你的 PDF 中有具体实验主题（如 “PL/0 语言编译器前端实现”“C 语言子集词法分析器”）、特殊要求（如指定语言、工具、提交格式），可补充说明，我会针对性调整；

2. 代码示例均为简化版，需根据实际需求修改（如扩展关键字表、完善 FIRST/FOLLOW 集计算、补充栈的实现）；

3. 可直接将本手册复制到 Word/LaTeX 中，添加目录、截图、公式后生成 PDF，满足提交要求。

需要我帮你针对某个具体实验模块（如 “SLR (1) 语法分析器实现”“DFA 最小化代码补充”）进一步细化步骤或代码吗？